{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"End2End_Models","provenance":[],"collapsed_sections":["vgP5BaUWN7g3","9yMITcOcNhFe","DD2tVJK5N4k0","zAWZTvkyODJ5","gQQZSM6POh4h","jh8u2NJgPDcq"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"lTG5wXfkK5PQ","executionInfo":{"status":"ok","timestamp":1639539085464,"user_tz":360,"elapsed":12668,"user":{"displayName":"Nikhitha Reddeddy","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03477990533991520713"}}},"source":["import torch\n","import torchvision\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from google.colab import drive\n","import os\n","import soundfile as sf\n","import librosa\n","import glob\n","from sklearn import metrics\n","from scipy.optimize import brentq\n","from scipy.interpolate import interp1d\n","from sklearn.metrics import roc_auc_score"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cxDZwa2QK6-d","executionInfo":{"status":"ok","timestamp":1639539098429,"user_tz":360,"elapsed":12971,"user":{"displayName":"Nikhitha Reddeddy","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03477990533991520713"}},"outputId":"c7883073-69d0-46e7-9e7f-5591bad6924f"},"source":["drive.mount('/content/drive', force_remount=True)"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"id":"e4BDIiHqK-nG","executionInfo":{"status":"ok","timestamp":1639539100037,"user_tz":360,"elapsed":134,"user":{"displayName":"Nikhitha Reddeddy","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03477990533991520713"}}},"source":["os.chdir('/content/drive/My Drive/Courses/CS545_MLSP/CS545_MLSP_Project')"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iQ-lRf6ar5K5"},"source":["## TSSDNet Models\n","\n"]},{"cell_type":"markdown","source":["## Inception model"],"metadata":{"id":"_hHf6TPfN25j"}},{"cell_type":"code","metadata":{"id":"ZvpxvYhMLHb6","executionInfo":{"status":"ok","timestamp":1639539103597,"user_tz":360,"elapsed":106,"user":{"displayName":"Nikhitha Reddeddy","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03477990533991520713"}}},"source":["class DilatedCovModule(nn.Module):\n","    def __init__(self, channels_in, channels_out):\n","        super().__init__()\n","\n","        channels_out = int(channels_out/4)\n","        self.cv1 = nn.Conv1d(in_channels=channels_in, out_channels=channels_out, bias=False, kernel_size=3, dilation=1, padding=1)\n","        self.cv2 = nn.Conv1d(in_channels=channels_in, out_channels=channels_out, bias=False, kernel_size=3, dilation=2, padding=2)\n","        self.cv4 = nn.Conv1d(in_channels=channels_in, out_channels=channels_out, bias=False, kernel_size=3, dilation=4, padding=4)\n","        self.cv8 = nn.Conv1d(in_channels=channels_in, out_channels=channels_out, bias=False, kernel_size=3, dilation=8, padding=8)\n","        self.bn1 = nn.BatchNorm1d(channels_out)\n","        self.bn2 = nn.BatchNorm1d(channels_out)\n","        self.bn4 = nn.BatchNorm1d(channels_out)\n","        self.bn8 = nn.BatchNorm1d(channels_out)\n","\n","    def forward(self, xx):\n","        xx1 = F.relu(self.bn1(self.cv1(xx)))\n","        xx2 = F.relu(self.bn2(self.cv2(xx)))\n","        xx4 = F.relu(self.bn4(self.cv4(xx)))\n","        xx8 = F.relu(self.bn8(self.cv8(xx)))\n","        yy = torch.cat((xx1, xx2, xx4, xx8), dim=1)\n","        return yy\n","        \n","class DilatedNet(nn.Module):  # Inc-TSSDNet\n","    def __init__(self):\n","        super().__init__()\n","        self.conv1 = nn.Conv1d(in_channels=1, out_channels=16, kernel_size=7, padding=3, bias=False)\n","        self.bn1 = nn.BatchNorm1d(16)\n","\n","        self.DCM1 = DilatedCovModule(channels_in=16, channels_out=32)\n","        self.DCM2 = DilatedCovModule(channels_in=32, channels_out=64)\n","        self.DCM3 = DilatedCovModule(channels_in=64, channels_out=128)\n","        self.DCM4 = DilatedCovModule(channels_in=128, channels_out=128)\n","\n","        self.fc1 = nn.Linear(in_features=128, out_features=64)\n","        self.fc2 = nn.Linear(in_features=64, out_features=32)\n","        self.out = nn.Linear(in_features=32, out_features=2)\n","\n","    def forward(self, x):\n","        x = F.relu(self.bn1(self.conv1(x)))\n","        x = F.max_pool1d(x, kernel_size=4)\n","\n","        x = F.max_pool1d(self.DCM1(x), kernel_size=4)\n","        x = F.max_pool1d(self.DCM2(x), kernel_size=4)\n","        x = F.max_pool1d(self.DCM3(x), kernel_size=4)\n","        # x = F.max_pool1d(self.DCM4(x), kernel_size=x.shape[-1])\n","        x = F.max_pool1d(self.DCM4(x), kernel_size=375)\n","\n","        x = torch.flatten(x, start_dim=1)\n","        x = F.relu(self.fc1(x))\n","        x = F.relu(self.fc2(x))\n","        x = self.out(x)\n","        return x\n"],"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["## Resnet Model"],"metadata":{"id":"vgP5BaUWN7g3"}},{"cell_type":"code","metadata":{"id":"gUU2vs0pLO4Z"},"source":["# ResNet-style module\n","# class RSM1D(nn.Module):\n","#     def __init__(self, channels_in=None, channels_out=None):\n","#         super().__init__()\n","#         self.channels_in = channels_in\n","#         self.channels_out = channels_out\n","\n","#         self.conv1 = nn.Conv1d(in_channels=channels_in, out_channels=channels_out, bias=False, kernel_size=3, padding=1)\n","#         self.conv2 = nn.Conv1d(in_channels=channels_out, out_channels=channels_out, bias=False, kernel_size=3, padding=1)\n","#         self.conv3 = nn.Conv1d(in_channels=channels_out, out_channels=channels_out, bias=False, kernel_size=3, padding=1)\n","\n","#         self.bn1 = nn.BatchNorm1d(channels_out)\n","#         self.bn2 = nn.BatchNorm1d(channels_out)\n","#         self.bn3 = nn.BatchNorm1d(channels_out)\n","\n","#         self.nin = nn.Conv1d(in_channels=channels_in, out_channels=channels_out, bias=False, kernel_size=1)\n","\n","#     def forward(self, xx):\n","#         yy = F.relu(self.bn1(self.conv1(xx)))\n","#         yy = F.relu(self.bn2(self.conv2(yy)))\n","#         yy = self.conv3(yy)\n","#         xx = self.nin(xx)\n","\n","#         xx = self.bn3(xx + yy)\n","#         xx = F.relu(xx)\n","#         return xx\n","\n","\n","# class RSM2D(nn.Module):\n","#     def __init__(self, channels_in=None, channels_out=None):\n","#         super().__init__()\n","#         self.channels_in = channels_in\n","#         self.channels_out = channels_out\n","\n","#         self.conv1 = nn.Conv2d(in_channels=channels_in, out_channels=channels_out, bias=False, kernel_size=3, padding=1)\n","#         self.conv2 = nn.Conv2d(in_channels=channels_out, out_channels=channels_out, bias=False, kernel_size=3, padding=1)\n","#         self.conv3 = nn.Conv2d(in_channels=channels_out, out_channels=channels_out, bias=False, kernel_size=3, padding=1)\n","\n","#         self.bn1 = nn.BatchNorm2d(channels_out)\n","#         self.bn2 = nn.BatchNorm2d(channels_out)\n","#         self.bn3 = nn.BatchNorm2d(channels_out)\n","\n","#         self.nin = nn.Conv2d(in_channels=channels_in, out_channels=channels_out, bias=False, kernel_size=1)\n","\n","#     def forward(self, xx):\n","#         yy = F.relu(self.bn1(self.conv1(xx)))\n","#         yy = F.relu(self.bn2(self.conv2(yy)))\n","#         yy = self.conv3(yy)\n","#         xx = self.nin(xx)\n","\n","#         xx = self.bn3(xx + yy)\n","#         xx = F.relu(xx)\n","#         return xx\n","\n","\n","# class SSDNet1D(nn.Module):  # Res-TSSDNet\n","#     def __init__(self):\n","#         super().__init__()\n","#         self.conv1 = nn.Conv1d(in_channels=1, out_channels=16, kernel_size=7, padding=3, bias=False)\n","#         self.bn1 = nn.BatchNorm1d(16)\n","\n","#         self.RSM1 = RSM1D(channels_in=16, channels_out=32)\n","#         self.RSM2 = RSM1D(channels_in=32, channels_out=64)\n","#         self.RSM3 = RSM1D(channels_in=64, channels_out=128)\n","#         self.RSM4 = RSM1D(channels_in=128, channels_out=128)\n","\n","#         self.fc1 = nn.Linear(in_features=128, out_features=64)\n","#         self.fc2 = nn.Linear(in_features=64, out_features=32)\n","#         self.out = nn.Linear(in_features=32, out_features=2)\n","\n","#     def forward(self, x):\n","#         x = F.relu(self.bn1(self.conv1(x)))\n","#         x = F.max_pool1d(x, kernel_size=4)\n","\n","#         # stacked ResNet-Style Modules\n","#         x = self.RSM1(x)\n","#         x = F.max_pool1d(x, kernel_size=4)\n","#         x = self.RSM2(x)\n","#         x = F.max_pool1d(x, kernel_size=4)\n","#         x = self.RSM3(x)\n","#         x = F.max_pool1d(x, kernel_size=4)\n","#         x = self.RSM4(x)\n","#         # x = F.max_pool1d(x, kernel_size=x.shape[-1])\n","#         x = F.max_pool1d(x, kernel_size=375)\n","\n","#         x = torch.flatten(x, start_dim=1)\n","#         x = F.relu(self.fc1(x))\n","#         x = F.relu(self.fc2(x))\n","#         x = self.out(x)\n","#         return x\n","\n","\n","# class SSDNet2D(nn.Module):  # 2D-Res-TSSDNet\n","#     def __init__(self):\n","#         super().__init__()\n","#         self.conv1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=7, padding=3, bias=False)\n","#         self.bn1 = nn.BatchNorm2d(16)\n","\n","#         self.RSM1 = RSM2D(channels_in=16, channels_out=32)\n","#         self.RSM2 = RSM2D(channels_in=32, channels_out=64)\n","#         self.RSM3 = RSM2D(channels_in=64, channels_out=128)\n","#         self.RSM4 = RSM2D(channels_in=128, channels_out=128)\n","\n","#         self.fc1 = nn.Linear(in_features=128, out_features=64)\n","#         self.fc2 = nn.Linear(in_features=64, out_features=32)\n","#         self.out = nn.Linear(in_features=32, out_features=2)\n","\n","#     def forward(self, x):\n","#         x = F.relu(self.bn1(self.conv1(x)))\n","#         x = F.max_pool2d(x, kernel_size=2)\n","\n","#         # stacked ResNet-Style Modules\n","#         x = self.RSM1(x)\n","#         x = F.max_pool2d(x, kernel_size=2)\n","#         x = self.RSM2(x)\n","#         x = F.max_pool2d(x, kernel_size=2)\n","#         x = self.RSM3(x)\n","#         x = F.max_pool2d(x, kernel_size=2)\n","#         x = self.RSM4(x)\n","\n","#         # x = F.avg_pool2d(x, kernel_size=(x.shape[-2], x.shape[-1]))\n","#         x = F.avg_pool2d(x, kernel_size=(27, 25))\n","\n","#         x = torch.flatten(x, start_dim=1)\n","#         x = F.relu(self.fc1(x))\n","#         x = F.relu(self.fc2(x))\n","#         x = self.out(x)\n","#         return x"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AKaP-E0vR8lm"},"source":["## Pre-trained model evaluations"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AvRAx1Y7LVGA","executionInfo":{"status":"ok","timestamp":1639539108699,"user_tz":360,"elapsed":1483,"user":{"displayName":"Nikhitha Reddeddy","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03477990533991520713"}},"outputId":"149b037c-d0b4-4395-916b-e5baf2b25f55"},"source":["device =  torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","\n","model_1 = DilatedNet()\n","\n","num_total_learnable_params_1 = sum(i.numel() for i in model_1.parameters() if i.requires_grad)\n","# print('Number of learnable params: {}.'.format(num_total_learnable_params_1))\n","\n","check_point = torch.load('./End2End-pretrained/Inc_TSSDNet_time_frame_28_ASVspoof2019_LA_Loss_0.0043_dEER_1.09%_eEER_4.04%.pth',map_location ='cpu')\n","model_1.load_state_dict(check_point['model_state_dict'])\n","model_1 = model_1.to(device)\n","model_1.eval()\n","\n","# model_2 = SSDNet1D()\n","# num_total_learnable_params_2 = sum(i.numel() for i in model_2.parameters() if i.requires_grad)\n","# # print('Number of learnable params: {}.'.format(num_total_learnable_params_2))\n","\n","# check_point = torch.load('./data/End2End-pretrained/Res_TSSDNet_time_frame_61_ASVspoof2019_LA_Loss_0.0017_dEER_0.74%_eEER_1.64%.pth',map_location ='cpu')\n","# model_2.load_state_dict(check_point['model_state_dict'])\n","# model_2 = model_2.to(device)\n","# model_2.eval()"],"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["DilatedNet(\n","  (conv1): Conv1d(1, 16, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)\n","  (bn1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (DCM1): DilatedCovModule(\n","    (cv1): Conv1d(16, 8, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n","    (cv2): Conv1d(16, 8, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,), bias=False)\n","    (cv4): Conv1d(16, 8, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,), bias=False)\n","    (cv8): Conv1d(16, 8, kernel_size=(3,), stride=(1,), padding=(8,), dilation=(8,), bias=False)\n","    (bn1): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (bn2): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (bn4): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (bn8): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  )\n","  (DCM2): DilatedCovModule(\n","    (cv1): Conv1d(32, 16, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n","    (cv2): Conv1d(32, 16, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,), bias=False)\n","    (cv4): Conv1d(32, 16, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,), bias=False)\n","    (cv8): Conv1d(32, 16, kernel_size=(3,), stride=(1,), padding=(8,), dilation=(8,), bias=False)\n","    (bn1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (bn2): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (bn4): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (bn8): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  )\n","  (DCM3): DilatedCovModule(\n","    (cv1): Conv1d(64, 32, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n","    (cv2): Conv1d(64, 32, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,), bias=False)\n","    (cv4): Conv1d(64, 32, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,), bias=False)\n","    (cv8): Conv1d(64, 32, kernel_size=(3,), stride=(1,), padding=(8,), dilation=(8,), bias=False)\n","    (bn1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (bn2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (bn4): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (bn8): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  )\n","  (DCM4): DilatedCovModule(\n","    (cv1): Conv1d(128, 32, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n","    (cv2): Conv1d(128, 32, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,), bias=False)\n","    (cv4): Conv1d(128, 32, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,), bias=False)\n","    (cv8): Conv1d(128, 32, kernel_size=(3,), stride=(1,), padding=(8,), dilation=(8,), bias=False)\n","    (bn1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (bn2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (bn4): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (bn8): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  )\n","  (fc1): Linear(in_features=128, out_features=64, bias=True)\n","  (fc2): Linear(in_features=64, out_features=32, bias=True)\n","  (out): Linear(in_features=32, out_features=2, bias=True)\n",")"]},"metadata":{},"execution_count":7}]},{"cell_type":"markdown","metadata":{"id":"IZ8xTvZNSBBu"},"source":["## Loading audio files\n","\n","Audios of duration upto 6 sec are considered and those with less than 6 sec  are padded with zeros"]},{"cell_type":"code","metadata":{"id":"Re9HYbgTLtu1","executionInfo":{"status":"ok","timestamp":1639539110595,"user_tz":360,"elapsed":128,"user":{"displayName":"Nikhitha Reddeddy","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03477990533991520713"}}},"source":["def load_audios(file_path, index):\n","  sample, _ = librosa.load(file_path + str(index) +'.wav',duration = 6.0)\n","  sample = torch.tensor(sample, dtype=torch.float32)\n","  sample = torch.unsqueeze(sample, 0)\n","  sample = torch.unsqueeze(sample, 0)\n","  label = torch.tensor(1, dtype=torch.int64)\n","  label = torch.unsqueeze(label, 0)\n","  return sample, label\n","\n","def load_flac(file_path,index):\n","  sample, _ = librosa.load(file_path + str(index) +'.flac',duration = 6.0)\n","  sample = torch.tensor(sample, dtype=torch.float32)\n","  sample = torch.unsqueeze(sample, 0)\n","  sample = torch.unsqueeze(sample, 0)\n","  label = torch.tensor(1, dtype=torch.int64)\n","  label = torch.unsqueeze(label, 0)\n","  return sample, label\n","\n","def load_for(file_path,label):\n","  sample,_ = librosa.load(file_path ,duration = 6.0)\n","  sample = torch.tensor(sample, dtype=torch.float32)\n","  sample = torch.unsqueeze(sample, 0)\n","  sample = torch.unsqueeze(sample, 0)\n","  label = torch.tensor(label, dtype=torch.int64)\n","  label = torch.unsqueeze(label, 0)\n","  return sample, label\n"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"ko7sj9WALYdv","executionInfo":{"status":"ok","timestamp":1639539112566,"user_tz":360,"elapsed":145,"user":{"displayName":"Nikhitha Reddeddy","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03477990533991520713"}}},"source":["def cal_accuracies(file_path, model, samples):\n","  \"\"\"\n","    probs: tensor, number of samples * 3, containing softmax probabilities\n","    row wise: [genuine prob (0), fake prob (1), label]\n","  \"\"\"\n","  with torch.no_grad():\n","    softmax_acc = 0\n","    num_files = 0\n","    probs = torch.empty(0, 3).to(device)\n","    \n","    test_sample = []\n","    test_label = []\n","\n","    target_len = 132300 \n","\n","    if('LA' in file_path):\n","      for i in range(1,samples):\n","        s,l = load_flac(file_path, i)\n","        if(s.shape[2]<target_len):\n","          s = F.pad(s,(target_len - s.size(2), 0))\n","        test_sample.append(s)\n","        test_label.append(l)\n","    else:\n","      for i in range(1,samples):\n","        s,l = load_audios(file_path, i)\n","        if(s.shape[2]<target_len):\n","          s = F.pad(s,(target_len - s.size(2), 0))\n","        test_sample.append(s)\n","        test_label.append(l)\n","\n","    test_data = torch.Tensor(len(test_label), 1, target_len )\n","    torch.cat(test_sample, out=test_data)\n","\n","    test_label = torch.IntTensor(test_label)\n","\n","    test_data = test_data.to(device)\n","    test_label = test_label.to(device)\n","    print(test_data.shape)\n","    num_files += len(test_label)\n","\n","    infer = model(test_data)\n","    t1 = F.softmax(infer, dim=1)\n","    t2 = test_label.unsqueeze(-1)\n","    row = torch.cat((t1, t2), dim=1)\n","    probs = torch.cat((probs, row), dim=0)\n","    infer = infer.argmax(dim=1)\n","    print(\"True:\",test_label)\n","    print(\"Preds:\",infer)\n","\n","    softmax_acc = infer.eq(test_label).sum().item()\n","\n","    softmax_acc = softmax_acc / num_files\n","\n","  return softmax_acc, infer, probs.to('cpu')"],"execution_count":9,"outputs":[]},{"cell_type":"code","source":["def cal_accuracies_for(filepath, filetype):\n","  \"\"\"\n","    probs: tensor, number of samples * 3, containing softmax probabilities\n","    row wise: [genuine prob (0), fake prob (1), label]\n","  \"\"\"\n","  if('FoR' in filepath):\n","    file_path_fake = filepath + '/Fake'\n","    file_path_real = filepath + '/Real'\n","  else:\n","    file_path_fake = filepath + '/fake/LA_Fake'\n","    file_path_real = filepath + '/real/la'\n","\n","  \n","  fake_samples = []\n","  fake_labels = []\n","  real_samples = []\n","  real_labels = []\n","\n","  fileCount = 0\n","  target_len = 132300\n","\n","  for filename in glob.glob(os.path.join(file_path_fake, filetype)):\n","    fileCount += 1\n","    s, l = load_for(filename,1)\n","    if(s.shape[2]<target_len):\n","          s = F.pad(s,(target_len - s.size(2), 0))\n","    fake_samples.append(s)\n","    fake_labels.append(l)\n","\n","  fake_data = torch.Tensor(len(fake_labels), 1, target_len)\n","  torch.cat(fake_samples, out=fake_data)\n","  fake_data = fake_data.to(device)\n","\n","  fake_labels = torch.IntTensor(fake_labels)\n","  fake_labels = fake_labels.to(device)\n","\n","  for filename in glob.glob(os.path.join(file_path_real, filetype)):\n","      fileCount += 1\n","      s, l = load_for(filename,1)\n","      if(s.shape[2]<target_len):\n","            s = F.pad(s,(target_len - s.size(2), 0))\n","      real_samples.append(s)\n","      real_labels.append(0)\n","\n","  real_data = torch.Tensor(len(real_labels), 1, target_len)\n","  torch.cat(real_samples, out=real_data)\n","  real_data = real_data.to(device)\n","\n","  real_labels = torch.IntTensor(real_labels)\n","  real_labels = real_labels.to(device)\n","\n","  data = torch.vstack((fake_data,real_data))\n","  labels = torch.hstack((fake_labels,real_labels))\n","\n","  print(data.shape)\n","  print(labels.shape)\n","\n","  with torch.no_grad():\n","    softmax_acc = 0\n","    probs = torch.empty(0, 3).to(device)\n","\n","    infer = model_1(data)\n","    t1 = F.softmax(infer, dim=1)\n","    t2 = labels.unsqueeze(-1)\n","    row = torch.cat((t1, t2), dim=1)\n","    probs = torch.cat((probs, row), dim=0)\n","    infer = infer.argmax(dim=1)\n","    softmax_acc = infer.eq(labels).sum().item()\n","\n","    softmax_acc = softmax_acc / fileCount\n","\n","  return softmax_acc, infer, probs.to('cpu')"],"metadata":{"id":"9QL1U7zbl8cz","executionInfo":{"status":"ok","timestamp":1639543703963,"user_tz":360,"elapsed":142,"user":{"displayName":"Nikhitha Reddeddy","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03477990533991520713"}}},"execution_count":35,"outputs":[]},{"cell_type":"code","source":["def cal_roc_eer(probs, show_plot=True):\n","    \"\"\"\n","    probs: tensor, number of samples * 3, containing softmax probabilities\n","    row wise: [genuine prob, fake prob, label]\n","    TP: True Fake\n","    FP: False Fake\n","    \"\"\"\n","\n","    all_labels = probs[:, 2]\n","    zero_index = torch.nonzero((all_labels == 0)).squeeze(-1)\n","    one_index = torch.nonzero(all_labels).squeeze(-1)\n","    zero_probs = probs[zero_index, 0]\n","    one_probs = probs[one_index, 0]\n","\n","    threshold_index = torch.linspace(-0.1, 1.01, 10000)\n","    tpr = torch.zeros(len(threshold_index),)\n","    fpr = torch.zeros(len(threshold_index),)\n","    cnt = 0\n","    for i in threshold_index:\n","        tpr[cnt] = one_probs.le(i).sum().item()/len(one_probs)\n","        fpr[cnt] = zero_probs.le(i).sum().item()/len(zero_probs)\n","        cnt += 1\n","\n","    sum_rate = tpr + fpr\n","    distance_to_one = torch.abs(sum_rate - 1)\n","    eer_index = distance_to_one.argmin(dim=0).item()\n","    eer = 0.5*(fpr[eer_index] + 1 - tpr[eer_index]).numpy()\n","    auc = metrics.auc(fpr, tpr)\n","\n","    return eer,auc"],"metadata":{"id":"TCoDUCuyJHaV","executionInfo":{"status":"ok","timestamp":1639541484176,"user_tz":360,"elapsed":160,"user":{"displayName":"Nikhitha Reddeddy","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03477990533991520713"}}},"execution_count":29,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9yMITcOcNhFe"},"source":["## WaveNet"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hVrO1KqhNkVD","executionInfo":{"status":"ok","timestamp":1639439885946,"user_tz":360,"elapsed":5358,"user":{"displayName":"Nikhitha Reddeddy","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03477990533991520713"}},"outputId":"bce8314d-84e1-4974-e29b-042639dc24b5"},"source":["file_path = './Code/data/test/fake/WaveNet/Audio_'\n","samples = 10\n","accuracy_m1, infer, probs = cal_accuracies(file_path, model_1,samples)\n","print(\"Accuracy: \", accuracy_m1*100)\n","\n","# accuracy_m2, infer, probs = cal_accuracies(file_path, model_2,samples)\n","# print(\"Accuracy: \", accuracy_m2*100)\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([9, 1, 132300])\n","True: tensor([1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n","Preds: tensor([1, 1, 1, 1, 1, 1, 1, 1, 1])\n","Accuracy:  100.0\n"]}]},{"cell_type":"markdown","metadata":{"id":"DD2tVJK5N4k0"},"source":["## WaveRNN"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mrs0YdNuNpu2","executionInfo":{"status":"ok","timestamp":1639439894568,"user_tz":360,"elapsed":4774,"user":{"displayName":"Nikhitha Reddeddy","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03477990533991520713"}},"outputId":"f8f9b66b-c6df-42bf-8b96-0d44fc3d3b08"},"source":["file_path = './Code/data/test/fake/WaveRNN/Audio_'\n","samples = 13\n","\n","accuracy_m1, infer, probs = cal_accuracies(file_path, model_1,samples)\n","print(\"Accuracy: \", accuracy_m1*100)\n","\n","# accuracy_m2, infer, probs = cal_accuracies(file_path, model_2,samples)\n","# print(\"Accuracy: \", accuracy_m2*100)\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([12, 1, 132300])\n","True: tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n","Preds: tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n","Accuracy:  100.0\n"]}]},{"cell_type":"markdown","metadata":{"id":"zAWZTvkyODJ5"},"source":["## FastSpeech\n","\n","**FastSpeech contains only 8 audio files, change the range of for loop while exceuting**\n","\n","\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rIEPTFYyN_8T","executionInfo":{"status":"ok","timestamp":1639439912321,"user_tz":360,"elapsed":2976,"user":{"displayName":"Nikhitha Reddeddy","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03477990533991520713"}},"outputId":"db773bb9-7aaa-4ea0-ba11-a671f9f5cf1d"},"source":["file_path = './Code/data/test/fake/FastSpeech/FS_'\n","samples = 9\n","\n","accuracy_m1, infer, probs = cal_accuracies(file_path, model_1,samples)\n","print(\"Accuracy: \", accuracy_m1*100)\n","\n","# accuracy_m2, infer, probs = cal_accuracies(file_path, model_2,samples)\n","# print(\"Accuracy: \", accuracy_m2*100)\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([8, 1, 132300])\n","True: tensor([1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n","Preds: tensor([1, 1, 1, 1, 1, 1, 1, 1])\n","Accuracy:  100.0\n"]}]},{"cell_type":"markdown","metadata":{"id":"gQQZSM6POh4h"},"source":["## WaveGlow&Tacotron"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EaUsAJplOZyA","executionInfo":{"status":"ok","timestamp":1639439926388,"user_tz":360,"elapsed":3107,"user":{"displayName":"Nikhitha Reddeddy","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03477990533991520713"}},"outputId":"284c8d7b-837e-44f2-8b72-a9fb2c3955c4"},"source":["file_path = './Code/data/test/fake/Tacotron&Waveglow/audio'\n","samples = 10\n","\n","accuracy_m1, infer, probs = cal_accuracies(file_path, model_1,samples)\n","print(\"Accuracy: \", accuracy_m1*100)\n","\n","# accuracy_m2, infer, probs = cal_accuracies(file_path, model_2,samples)\n","# print(\"Accuracy: \", accuracy_m2*100)\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([9, 1, 132300])\n","True: tensor([1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n","Preds: tensor([1, 1, 1, 1, 1, 1, 1, 1, 0])\n","Accuracy:  88.88888888888889\n"]}]},{"cell_type":"markdown","metadata":{"id":"jh8u2NJgPDcq"},"source":["## LA_Fake"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mUu9sNa4OrPE","executionInfo":{"status":"ok","timestamp":1639543890175,"user_tz":360,"elapsed":2929,"user":{"displayName":"Nikhitha Reddeddy","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03477990533991520713"}},"outputId":"1a7b758b-bf18-45a1-be10-b794032172d8"},"source":["file_path = './Code/data/test/fake/LA_Fake/LA_F'\n","samples = 21\n","\n","accuracy_m1, infer, probs = cal_accuracies(file_path, model_1,samples)\n","print(\"Accuracy: \", accuracy_m1*100)\n","\n","# accuracy_m2, infer, probs = cal_accuracies(file_path, model_2,samples)\n","# print(\"Accuracy: \", accuracy_m2*100)\n"],"execution_count":40,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([20, 1, 132300])\n","True: tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n","       dtype=torch.int32)\n","Preds: tensor([0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0])\n","Accuracy:  35.0\n"]}]},{"cell_type":"markdown","source":["## FoR Test Data"],"metadata":{"id":"tkPqhxVfPHAl"}},{"cell_type":"code","source":["accuracy_m1, infer, probs = cal_accuracies_for('./Code/data/FoR/Testing','*.wav')\n","print(\"Accuracy: \", accuracy_m1*100)\n","eer, roc = cal_roc_eer(probs,False)\n","print(eer,roc)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xZrnQJb-PDK4","executionInfo":{"status":"ok","timestamp":1639543786997,"user_tz":360,"elapsed":21719,"user":{"displayName":"Nikhitha Reddeddy","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03477990533991520713"}},"outputId":"65a07b56-3aaf-4c64-d57f-042ca074e532"},"execution_count":39,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([200, 1, 132300])\n","torch.Size([200])\n","Accuracy:  64.5\n","0.375 0.5876500010490417\n"]}]},{"cell_type":"code","source":["accuracy_m1, infer, probs = cal_accuracies_for('./Code/data/test','*.flac')\n","print(\"Accuracy: \", accuracy_m1*100)\n","\n","eer, roc = cal_roc_eer(probs,False)\n","print(eer,roc)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"u2fGpm4mKUIH","executionInfo":{"status":"ok","timestamp":1639543762301,"user_tz":360,"elapsed":19996,"user":{"displayName":"Nikhitha Reddeddy","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03477990533991520713"}},"outputId":"41ab32d6-b058-4306-cbad-73a2aac1688c"},"execution_count":38,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([40, 1, 132300])\n","torch.Size([40])\n","Accuracy:  47.5\n","0.3999999761581421 0.6074999570846558\n"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"91nHfDtObB6L"},"execution_count":null,"outputs":[]}]}